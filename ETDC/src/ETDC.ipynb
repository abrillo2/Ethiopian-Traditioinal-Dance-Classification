{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import sys, os\n",
    "\n",
    "#from skimage.morphology import skeletonize\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.util import invert\n",
    "from skimage import morphology, filters\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaration of global variables\n",
    "#dataset path\n",
    "pathDS = \"../dataset/\"\n",
    "\n",
    "#initialize skeleton models and variables for individual frame skeleton detection\n",
    "protoFile = \"../MPI/pose_deploy_linevec.prototxt\"\n",
    "weightsFile = \"../MPI/pose_iter_160000.caffemodel\"\n",
    "#load pretrained models for single person joint detection\n",
    "net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n",
    "jointCount0 = 15\n",
    "POSE_PAIRS =[ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "#directories list of dataset for each class\n",
    "category = [cat for cat in os.listdir('../dataset')]\n",
    "'''mutliple dancers joint keypoint extraction weight and network model trained on coco'''\n",
    "\n",
    "#load weight and network files\n",
    "cocoProtoFile = \"../coco/pose_deploy_linevec.prototxt\"\n",
    "cocoCaffeWeightsFile = \"../coco/pose_iter_440000.caffemodel\"\n",
    "jointCount = 18\n",
    "\n",
    "#initialize skeleton pair nodes and labels based on coco training dataset\n",
    "keypointPairs = [[1,2], [1,5], [2,3], [3,4], [5,6], [6,7],[1,8], [8,9], [9,10], [1,11], [11,12], [12,13],[1,0], [0,14], [14,16], [0,15], [15,17],[2,17], [5,16] ]\n",
    "keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho', 'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip','L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']                  \n",
    "keypointPairsIndex = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44],[19,20], [21,22], [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], [55,56], [37,38], [45,46]]\n",
    "keypointPairsColor = [ [0,100,255], [0,100,255], [0,255,255], [0,100,255], [0,255,255], [0,100,255],[0,255,0], [255,200,100], [255,0,255], [0,255,0], [255,200,100], [255,0,255],[0,0,255], [255,0,0], [200,200,0], [255,0,0], [200,200,0], [0,0,0]]\n",
    "#initialize the pre-trained coco network using cv dnn, weight from caffe file, network from protofile\n",
    "cocoDnn = cv2.dnn.readNetFromCaffe(cocoProtoFile, cocoCaffeWeightsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = [clip for clip in os.listdir('../dataset/shoa/newd/')]\n",
    "saveDir = '../dataset/shoa/newd/frames/'\n",
    "\n",
    "\n",
    "def extractFrameData():\n",
    "    i = 0\n",
    "    for clip in clips:\n",
    "        \n",
    "        if str(clip) == \"frames\":\n",
    "            continue\n",
    "        \n",
    "        print (clip)\n",
    "        img =cv2.VideoCapture(\"../dataset/shoa/newd/\" + str(clip))\n",
    "        path = saveDir + \"clip\" + str(i) + \"/\"\n",
    "        \n",
    "        isExist = os.path.exists(path)\n",
    "        \n",
    "        if(not isExist):\n",
    "            \n",
    "            os.makedirs(path)\n",
    "    \n",
    "        i+=1\n",
    "        extractClipFrame(img,path)\n",
    "            \n",
    "        \n",
    "        \n",
    "def extractClipFrame(clip,path):\n",
    "    \n",
    "    j = 0\n",
    "    while True:\n",
    "        # read video frames\n",
    "        retval, frame = clip.read()\n",
    "        # check whether the frames have been grabbed\n",
    "        if not retval:\n",
    "            return\n",
    "        # resize video frames\n",
    "        frame = cv2.resize(frame, (640, 360))\n",
    "\n",
    "        #skeletonizeDancePose(frame,0.1)    \n",
    "        cv2.imwrite(path + \"/\" + str(j)+ '.jpg',frame)\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-4-7.mp4\n",
      "6-400-403.mkv\n",
      "4-10-13.mkv\n",
      "3-29-31.mp4\n",
      "4-13-16.mkv\n",
      "2-30-50.mkv\n",
      "3-88-90.mp4\n",
      "3-200-201.mp4\n",
      "3-247-250.mp4\n",
      "6-110-112.mkv\n",
      "5-380-387.mkv\n",
      "4-129-136.mkv\n",
      "5-314-334.mkv\n",
      "5-361-371.mkv\n"
     ]
    }
   ],
   "source": [
    "extractFrameData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENERAL HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hlper function id:HELPER 0.1\n",
    "#for sorting files in dir \n",
    "def checkFileString(fileString):\n",
    "    return int(fileString) if fileString.isdigit() else fileString\n",
    "def natural_keys(fileList):\n",
    "    '''\n",
    "    alist.sort(key=natural_keys) sorts in human order\n",
    "    http://nedbatchelder.com/blog/200712/human_sorting.html\n",
    "    (See Toothy's implementation in the comments)\n",
    "    '''\n",
    "    return [ checkFileString(i) for i in re.split(r'(\\d+)', fileList) ]\n",
    "\n",
    "#hlper function id:HELPER 0.2\n",
    "#sort dancer position based on neck x coordinate left to right\n",
    "def sortDancerPosition(data):\n",
    "    #initialize imp vals\n",
    "    data2 = data.copy()\n",
    "    index = 0\n",
    "    #zeros numpy array to hold the sorted data\n",
    "    orderedDancers = np.zeros((data2.shape[0], 18,2))\n",
    "    \n",
    "    #get the target x coordinate float value and it's index\n",
    "    indexVal = [i for i in range(data2.shape[0])]\n",
    "    floatVal = []\n",
    "    for j in range(data2.shape[0]):\n",
    "        floatVal.append(data[j][1][0])\n",
    "\n",
    "    valIndexPair = dict(zip(floatVal, indexVal))\n",
    "    oValIndexPair = collections.OrderedDict(sorted(valIndexPair.items()))\n",
    "    #sort the dictionary based on x float value\n",
    "    oValIndexPair = collections.OrderedDict(sorted(valIndexPair.items()))\n",
    "    \n",
    "    orderedDancers = np.zeros((data2.shape[0], 18,2))\n",
    "    index = 0\n",
    "    for k, v in oValIndexPair.items():\n",
    "        orderedDancers[index] = data[v]\n",
    "        index+=1\n",
    "        \n",
    "    return orderedDancers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROBLEM SPECIFIC HELPER FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTION: HELPER 1.0\n",
    "SINGLE PERSON SKELETON EXTRACTOR FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for single person skeleton extraction\n",
    "def skeletonizeDancePose(fileName, thresh):\n",
    "    \n",
    "    img = cv2.imread(fileName)\n",
    "    frameWidth = img.shape[1]\n",
    "    frameHeight = img.shape[0]\n",
    "    frameCopy = np.copy(img)\n",
    "    threshold = 0.1\n",
    "    \n",
    "    #preprocess img for input\n",
    "    inpBlob = cv2.dnn.blobFromImage(img, 1.0 / 255, (368, 368),(0, 0, 0), swapRB=False, crop=False)\n",
    "    #feed the preprocessed img through the network\n",
    "    cocoDnn.setInput(inpBlob)\n",
    "    output = cocoDnn.forward()\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "    \n",
    "    # gather keypoints here\n",
    "    points = []\n",
    "    \n",
    "    #loop through possible 18 keypoints\n",
    "    for i in range(jointCount):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "\n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "\n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "\n",
    "        if prob > thresh :\n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(img, (int(x), int(y)), 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "\n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append((0,0))\n",
    "        \n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "\n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(img, points[partA], points[partB], (0, 255, 255), 3)\n",
    "    \n",
    "    return np.array(points)\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB))\n",
    "    plt.figure(figsize=[10,10])\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    #cv2.imshow(\"Subtraction result\", frame)\n",
    "    \n",
    "    #return the curent 18 body part point pose\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTION: HELPER 2.0\n",
    "MULTI PERSON SKELETON EXTRACTOR FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractKeypoints(fileName):\n",
    "    #initialize keypoint pairs and keypoint holders\n",
    "    validKeypointPairs = []\n",
    "    invalidKeypointPairs = []\n",
    "    detectedKeypoints = []\n",
    "    keypointsList = np.zeros((0,3))\n",
    "    keypointId = 0\n",
    "    threshold = 0.1\n",
    "    dancerKeypoints = -1 * np.ones((0, 19))\n",
    "    #initialize threshhold metrices for part affinities of joint flow and keypoints and interopolation points\n",
    "    interpSamples = 10\n",
    "    pafThresh = 0.1\n",
    "    keypointThresh = 0.7\n",
    "    #open frame and extract frame properties\n",
    "    img = cv2.imread(fileName)\n",
    "    imgWidth = img.shape[1]\n",
    "    imgHeight = img.shape[0]\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    #use CPU for dnn prediction\n",
    "    cocoDnn.setPreferableBackend(cv2.dnn.DNN_TARGET_CPU)\n",
    "    #prepare frame for keyframe estemation\n",
    "    inputH,inputW =368,int((368/imgHeight)*imgWidth)\n",
    "    #extract blobs from frame\n",
    "    connectedPixelPairs = cv2.dnn.blobFromImage(img, 1.0 / 255, (inputW, inputH),(0, 0, 0), swapRB=False, crop=False)\n",
    "    #feed blob to the coco network\n",
    "    cocoDnn.setInput(connectedPixelPairs)\n",
    "    output = cocoDnn.forward()\n",
    "    #detect keypoints\n",
    "    for joint in range(jointCount):\n",
    "        probMap = output[0,joint,:,:]\n",
    "        probMap = cv2.resize(probMap, (img.shape[1], img.shape[0]))\n",
    "        #extract keypoints using probabiliy map   \n",
    "        probMap2 = cv2.GaussianBlur(probMap,(3,3),0,0)\n",
    "        probMapMask = np.uint8(probMap2>threshold)\n",
    "        keypoints = []\n",
    "        #find blobs\n",
    "        mapContours, _ = cv2.findContours(probMapMask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        #for each blob find the maxima\n",
    "        for c in mapContours:\n",
    "            cMask = np.zeros(probMap2.shape)\n",
    "            cMask = cv2.fillConvexPoly(cMask, c, 1)\n",
    "            cMapMaskProb = probMap2 * cMask\n",
    "            _, maxVal, _, maxLoc = cv2.minMaxLoc(cMapMaskProb)\n",
    "            keypoints.append(maxLoc + (probMap[maxLoc[1], maxLoc[0]],))\n",
    "        \n",
    "        #print(\"Keypoints - {} : {}\".format(keypointsMapping[joint], keypoints))\n",
    "        keypointIds = []\n",
    "        for i in range(len(keypoints)):\n",
    "            keypointIds.append(keypoints[i] + (keypointId,))\n",
    "            keypointsList = np.vstack([keypointsList, keypoints[i]])\n",
    "            keypointId += 1\n",
    "\n",
    "        detectedKeypoints.append(keypointIds)\n",
    "    \n",
    "    #loop through keypoint paris\n",
    "    for k in range(len(keypointPairsIndex)):\n",
    "        #on each iteration create keypoint(body part) pairs\n",
    "        paf1 = output[0, keypointPairsIndex[k][0], :, :]\n",
    "        paf2 = output[0, keypointPairsIndex[k][1], :, :]\n",
    "        #resize to inputframe\n",
    "        paf1 = cv2.resize(paf1, (imgWidth, imgHeight))\n",
    "        paf2 = cv2.resize(paf2, (imgWidth, imgHeight))\n",
    "        # Find the keypoints for the current body part pairs\n",
    "        cand1 = detectedKeypoints[keypointPairs[k][0]]\n",
    "        cand2 = detectedKeypoints[keypointPairs[k][1]]\n",
    "        n1 = len(cand1)\n",
    "        n2 = len(cand2)\n",
    "        # If keypoints for the joint-pair is detected\n",
    "        # check every joint in cand1 with every joint in cand2\n",
    "        # Calculate the distance vector between the two joints\n",
    "        # Find the PAF values at a set of interpolated points between the joints\n",
    "        if( n1 != 0 and n2 != 0):\n",
    "            validKeypointPair = np.zeros((0,3))\n",
    "            for i in range(n1):\n",
    "                maxP=-1\n",
    "                maxScore = -1\n",
    "                found = 0\n",
    "                for j in range(n2):\n",
    "                    # Find a good pair vector points\n",
    "                    goodPair = np.subtract(cand2[j][:2], cand1[i][:2])\n",
    "                    norm = np.linalg.norm(goodPair)\n",
    "                    if norm:\n",
    "                        goodPair = goodPair / norm\n",
    "                    else:\n",
    "                        continue\n",
    "                    # Find interpolated point between two joints\n",
    "                    interpXY = list(zip(np.linspace(cand1[i][0], cand2[j][0], num=interpSamples),\n",
    "                                            np.linspace(cand1[i][1], cand2[j][1], num=interpSamples)))\n",
    "                    # find paf from interPXY\n",
    "                    interpPaf = []\n",
    "                    for k in range(len(interpXY)):\n",
    "                        interpPaf.append([paf1[int(round(interpXY[k][1])), int(round(interpXY[k][0]))],\n",
    "                                           paf2[int(round(interpXY[k][1])), int(round(interpXY[k][0]))] ]) \n",
    "                    # Find E\n",
    "                    pafScores = np.dot(interpPaf, goodPair)\n",
    "                    avgPafScores = sum(pafScores)/len(pafScores)\n",
    "                    \n",
    "                    # Check if the connection is valid\n",
    "                    # If the fraction of interpolated vectors aligned with PAF is higher then threshold it's a Valid Pair  \n",
    "                    if (len(np.where(pafScores > pafThresh)[0]) / interpSamples ) > keypointThresh :\n",
    "                        if avgPafScores > maxScore:\n",
    "                            maxP = j\n",
    "                            maxScore = avgPafScores\n",
    "                            found = 1\n",
    "                # Append the connection to the list\n",
    "                if found:            \n",
    "                    validKeypointPair = np.append(validKeypointPair, [[cand1[i][3], cand2[maxP][3], maxScore]], axis=0)\n",
    "\n",
    "            # Append the detected connections to the global list\n",
    "            validKeypointPairs.append(validKeypointPair)\n",
    "        else: # If no keypoints are detected\n",
    "            #print(\"No Connection : k = {}\".format(k))\n",
    "            invalidKeypointPairs.append(k)\n",
    "            validKeypointPairs.append([])\n",
    "    #get separate points for each dancers pose\n",
    "    for k in range(len(keypointPairsIndex)):\n",
    "        if k not in invalidKeypointPairs:\n",
    "            jointPart1 = validKeypointPairs[k][:,0]\n",
    "            jointPart2 = validKeypointPairs[k][:,1]\n",
    "            indexVal1, indexVal2 = np.array(keypointPairs[k])\n",
    "\n",
    "            for i in range(len(validKeypointPairs[k])): \n",
    "                found = 0\n",
    "                dancerIndex = -1\n",
    "                for j in range(len(dancerKeypoints)):\n",
    "                    if dancerKeypoints[j][indexVal1] == jointPart1[i]:\n",
    "                        dancerIndex = j\n",
    "                        found = 1\n",
    "                        break\n",
    "                if found:\n",
    "                    dancerKeypoints[dancerIndex][indexVal2] = jointPart2[i]\n",
    "                    dancerKeypoints[dancerIndex][-1] += keypointsList[jointPart2[i].astype(int), 2] + validKeypointPairs[k][i][2]\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(19)\n",
    "                    row[indexVal1] = jointPart1[i]\n",
    "                    row[indexVal2] = jointPart2[i]\n",
    "                    # add the keypoint_scores for the two keypoints and the paf_score \n",
    "                    row[-1] = sum(keypointsList[validKeypointPairs[k][i,:2].astype(int), 2]) + validKeypointPairs[k][i][2]\n",
    "                    dancerKeypoints = np.vstack([dancerKeypoints, row])\n",
    "    #result visualization\n",
    "    img2 = img.copy()\n",
    "    \n",
    "    #ordered keypoint and draw keypoint on image for visualization\n",
    "    orderedKeypoint = np.zeros((len(dancerKeypoints), 18,2))\n",
    "    \n",
    "    for i in range(17):\n",
    "        for n in range(len(dancerKeypoints)):\n",
    "            index = dancerKeypoints[n][np.array(keypointPairs[i])]\n",
    "            \n",
    "            for jp in index:\n",
    "                if(jp != -1):    \n",
    "                    jointPoint = np.int32(keypointsList[jp.astype(int)])\n",
    "                    \n",
    "                    #print(jointPoint[:2])\n",
    "                    \n",
    "                    orderedKeypoint[n][keypointPairs[i][np.where(index == jp)[0][0]]]=jointPoint[:2]\n",
    "            \n",
    "            if -1 in index:     \n",
    "                continue\n",
    "             \n",
    "            B = np.int32(keypointsList[index.astype(int), 0])\n",
    "            A = np.int32(keypointsList[index.astype(int), 1])\n",
    "\n",
    "            cv2.line(img2,(B[1], A[1]),(B[0], A[0]), keypointPairsColor[i], 3, cv2.LINE_AA)\n",
    "    \n",
    "    return(img2,orderedKeypoint)\n",
    "    plt.figure(figsize=[15,15])\n",
    "    plt.imshow(img2[:,:,[2,1,0]])\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HELPER FUNCTION: HELPER 3.0\n",
    "FUNCTION TO EXTRACT CLIP FRAMES AS AN IN PUT FOR MULTI PERSON SKELETON EXTRACTOR HELPER FUNCTION: HELPER 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to go through frame sequence in the dataset folder\n",
    "def passFrameSequence(multiPerson):\n",
    "    \n",
    "    modePathString = \"indvg\"\n",
    "    if(multiPerson):\n",
    "        \n",
    "        modePathString = \"frames\"\n",
    "    #class labels\n",
    "    classLabels = ['guraginga','gojjam',\"shoa\"]\n",
    "    frametracker = 0\n",
    "    clipTracker = 0\n",
    "    \n",
    "    for label in classLabels:\n",
    "        #currentFramePath\n",
    "        currentDSFramePath = os.path.join('../dataset', label + \"/\" + modePathString)\n",
    "        currentClipPath = [i for i in os.listdir(currentDSFramePath) if not i.startswith('.')]\n",
    "        currentClipPath.sort(key=natural_keys)\n",
    "        \n",
    "        #loop through each clips\n",
    "        for clip in currentClipPath:\n",
    "            \n",
    "            currentFramePath = [j for j in os.listdir(os.path.join(currentDSFramePath,clip)) if not j.startswith('.')]\n",
    "            currentFramePath.sort(key=natural_keys)\n",
    "            \n",
    "            timeStep = 0\n",
    "            dancerLen = 0\n",
    "            \n",
    "            curentFrameSequenceKeypointList = []\n",
    "            for frame in currentFramePath:\n",
    "                \n",
    "                if(timeStep==5): continue\n",
    "                fullPath = os.path.join(currentDSFramePath, clip)\n",
    "                frameName = os.path.join(fullPath, frame)\n",
    "                \n",
    "                if(not multiPerson):\n",
    "                    currentKeypoints = skeletonizeDancePose(frameName,0.1)\n",
    "                    curentFrameSequenceKeypointList.append(currentKeypoints)\n",
    "                    print(\"****** current frame being processed: \",frame + \" ******\\n\")\n",
    "                    timeStep+=1\n",
    "                    continue\n",
    "                \n",
    "                data = extractKeypoints(frameName) \n",
    "                \n",
    "                currentKeypoints = sortDancerPosition(data[1])\n",
    "                skeletonImg = data[0]\n",
    "\n",
    "                \n",
    "                if(timeStep == 0):\n",
    "                    dancerLen = currentKeypoints.shape[0]\n",
    "                    timeStep+=1\n",
    "                \n",
    "                print(\"****** current frame being processed: \",frame + \" ******\\n\")\n",
    "                print(\"****** Current dancers Numbers \" + str(currentKeypoints.shape[0]) + \" ******\")  \n",
    "                #check if dancer number is not curroptued\n",
    "                print( \"****** Prev dancers number = \" + str(dancerLen) + \"**********\")\n",
    "                print(\"******* clip name =      \" + clip + \" ******\\n\") \n",
    "                \n",
    "                if(currentKeypoints.shape[0] != dancerLen):\n",
    "                    timeStep = 0\n",
    "                    print(\"****** changed dancers    = \" + str(currentKeypoints.shape[0]) +  \"*******\")\n",
    "                    print(\"****** Changed clip name = \" + clip + \"=> \"+ frame + \" ***********\\n\") \n",
    "                    for j in range(dancerLen):\n",
    "                        dancerII = [] \n",
    "                        #print(len(curentFrameSequenceKeypointList))\n",
    "                        for k in range(len(curentFrameSequenceKeypointList)):\n",
    "\n",
    "                            currentStep = np.copy(curentFrameSequenceKeypointList[k][j])\n",
    "                            currentStep = currentStep.flatten()\n",
    "                            currentStepT = np.append(currentStep,k)\n",
    "                            currentStepL = np.append(currentStepT,label)\n",
    "                            dancerII.append(currentStepL)\n",
    "                        \n",
    "                        df = pd.DataFrame(dancerII)\n",
    "                        df.to_csv(\"trainX.csv\", index=False, mode='a', header=False)\n",
    "                        print(\"****** saved time sequenec    = \" + str(len(curentFrameSequenceKeypointList)) +  \"*******\")\n",
    "                        print(\"****** saved # of dancers = \" + str(dancerLen) + \"dancer :\"+ str(j) +  \"*******\\n\") \n",
    "                        dancerII.clear()\n",
    "                    curentFrameSequenceKeypointList.clear()\n",
    "                else:\n",
    "                    #stroe Current keypairs   \n",
    "                    curentFrameSequenceKeypointList.append(currentKeypoints)\n",
    "                    timeStep+=1\n",
    "            \n",
    "            if(not multiPerson):\n",
    "                dancerII = [] \n",
    "                #print(len(curentFrameSequenceKeypointList))\n",
    "                for k in range(len(curentFrameSequenceKeypointList)):\n",
    "                            \n",
    "                    currentStep = np.copy(curentFrameSequenceKeypointList[k])\n",
    "                    currentStep = currentStep.flatten()\n",
    "                    currentStepT = np.append(currentStep,k)\n",
    "                    currentStepL = np.append(currentStepT,label)\n",
    "                    dancerII.append(currentStepL)\n",
    "                 \n",
    "                df = pd.DataFrame(dancerII)\n",
    "                df.to_csv(\"trainX2.csv\", index=False, mode='a', header=False)\n",
    "                dancerII = []\n",
    "                print(\"****** \"+clip+\" saved time sequenec    = \" + str(len(curentFrameSequenceKeypointList)) +  \"*******\")\n",
    "                curentFrameSequenceKeypointList.clear()          \n",
    "                continue\n",
    "            \n",
    "            for j in range(dancerLen):\n",
    "                dancerII = [] \n",
    "                #print(len(curentFrameSequenceKeypointList))\n",
    "                for k in range(len(curentFrameSequenceKeypointList)):\n",
    "                            \n",
    "                    currentStep = np.copy(curentFrameSequenceKeypointList[k][j])\n",
    "                    currentStep = currentStep.flatten()\n",
    "                    currentStepT = np.append(currentStep,k)\n",
    "                    currentStepL = np.append(currentStepT,label)\n",
    "                    dancerII.append(currentStepL)\n",
    "                 \n",
    "                df = pd.DataFrame(dancerII)\n",
    "                df.to_csv(\"trainX.csv\", index=False, mode='a', header=False)\n",
    "                dancerII = []\n",
    "                print(\"****** saved time sequenec    = \" + str(len(curentFrameSequenceKeypointList)) +  \"*******\")\n",
    "                print(\"****** saved # of dancers = \" + str(currentKeypoints.shape[0])+ \"dancer :\"+ str(j)+  \"*******\\n\") \n",
    "            curentFrameSequenceKeypointList.clear()          \n",
    "\n",
    "\n",
    "#adding joint sequence to csv file for dataset\n",
    "def prepareFileDataset(keypoints,step):\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** current frame being processed:  0.jpg ******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data2 = passFrameSequence(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[306,  78],\n",
       "        [292, 109],\n",
       "        [208, 101],\n",
       "        [153, 140],\n",
       "        [180, 180],\n",
       "        [375, 109],\n",
       "        [417, 140],\n",
       "        [417, 180],\n",
       "        [250, 187],\n",
       "        [250, 250],\n",
       "        [264, 320],\n",
       "        [347, 180],\n",
       "        [361, 250],\n",
       "        [347, 320],\n",
       "        [292,  70],\n",
       "        [320,  70],\n",
       "        [250,  78],\n",
       "        [333,  70]])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
